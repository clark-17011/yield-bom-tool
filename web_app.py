import streamlit as st
import pandas as pd
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment
from openpyxl.utils import get_column_letter
import re
import unicodedata
import io
import matplotlib.pyplot as plt
import matplotlib
import platform

# ==========================================
# 0. åŸºç¤è¨­å®šèˆ‡å·¥å…· (Shared Utilities)
# ==========================================

# è¨­å®š Matplotlib å­—å‹ä»¥å…ä¸­æ–‡äº‚ç¢¼
def configure_chart_font():
    system_name = platform.system()
    if system_name == "Windows":
        plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial']
    elif system_name == "Darwin": # macOS
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang TC', 'Heiti TC']
    else:
        # Linux / Streamlit Cloud é€šå¸¸æ˜¯ Linux
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False 

configure_chart_font()

def normalize_str(x) -> str:
    if x is None: return ""
    s = str(x)
    s = unicodedata.normalize("NFKC", s)
    s = s.strip()
    s = re.sub(r"[^A-Za-z0-9]", "", s)
    return s.lower()

def parse_search_config(raw_text: str, is_space_or_mode: bool):
    if not raw_text.strip(): return []
    raw_text = raw_text.replace("ï¼Œ", ",")
    segments = [s.strip() for s in raw_text.split(',') if s.strip()]
    configs = []
    for seg in segments:
        if seg.startswith('[') and seg.endswith(']'):
            content = seg[1:-1].strip()
            sub_terms = [t.strip() for t in content.split() if t.strip()]
            if sub_terms:
                configs.append({'display': seg, 'terms': sub_terms})
            continue
        parts = [p.strip() for p in seg.split() if p.strip()]
        if not parts: continue
        if is_space_or_mode:
            for p in parts: configs.append({'display': p, 'terms': [p]})
        else:
            if len(parts) > 1:
                display_name = f"[{' '.join(parts)}]"
                configs.append({'display': display_name, 'terms': parts})
            else:
                configs.append({'display': parts[0], 'terms': [parts[0]]})
    
    seen = set()
    unique = []
    for c in configs:
        if c['display'] not in seen:
            unique.append(c)
            seen.add(c['display'])
    return unique

# ==========================================
# 1. Yield Report é‚è¼¯
# ==========================================

@st.cache_data(ttl=3600, show_spinner=False)
def load_yield_files(uploaded_files):
    """
    è®€å– Yield Report Excel æª”æ¡ˆï¼Œå»ºç«‹åŸå§‹è³‡æ–™èˆ‡æœå°‹ç´¢å¼•
    """
    raw_data = [] # å­˜æ”¾ (label, sheet_name, header, data_rows)
    row_texts = [] # å­˜æ”¾ (label, sheet_name, normalized_texts_list)
    
    total_sheets = 0
    
    for file in uploaded_files:
        label = file.name # ä½¿ç”¨æª”åä½œç‚ºæ¨™ç±¤
        try:
            wb = openpyxl.load_workbook(file, read_only=True, data_only=True)
            for sheet_name in wb.sheetnames:
                try:
                    ws = wb[sheet_name]
                    rows = list(ws.iter_rows(values_only=True))
                    if not rows: continue
                    header = rows[0]
                    data_rows = rows[1:]
                    if not data_rows: continue
                    
                    # å„²å­˜åŸå§‹æ•¸æ“š
                    raw_data.append({
                        "label": label,
                        "sheet": sheet_name,
                        "header": header,
                        "rows": data_rows
                    })
                    
                    # å»ºç«‹æœå°‹ç´¢å¼• (æ­£è¦åŒ–å­—ä¸²)
                    current_sheet_texts = []
                    for row in data_rows:
                        joined = "".join([str(c) if c is not None else "" for c in row])
                        current_sheet_texts.append(normalize_str(joined))
                    
                    row_texts.append({
                        "label": label,
                        "sheet": sheet_name,
                        "texts": current_sheet_texts
                    })
                    total_sheets += 1
                except: pass
            wb.close()
        except Exception as e:
            print(f"Error loading {label}: {e}")
            
    return raw_data, row_texts, total_sheets

def execute_yield_search(raw_data, row_texts, configs):
    """
    åŸ·è¡Œ Yield æœå°‹
    """
    if not configs: return pd.DataFrame(), set()

    prepared_configs = []
    for cfg in configs:
        norm_terms = [normalize_str(t) for t in cfg['terms'] if t.strip()]
        if norm_terms:
            prepared_configs.append({'display': cfg['display'], 'terms': norm_terms})

    all_rows_data = []
    found_display_names = set()
    
    # éæ­·æ‰€æœ‰å·²è®€å–çš„ Sheet
    # row_texts çµæ§‹: [{"label":..., "sheet":..., "texts": [...]}, ...]
    for idx, sheet_info in enumerate(row_texts):
        label = sheet_info["label"]
        sheet_name = sheet_info["sheet"]
        sheet_norm_texts = sheet_info["texts"]
        
        # å–å¾—å°æ‡‰çš„åŸå§‹è³‡æ–™
        # raw_data çµæ§‹èˆ‡ row_texts ç´¢å¼•å°æ‡‰ (å› ç‚ºæ˜¯é †åºè®€å–çš„)
        header = raw_data[idx]["header"]
        all_rows = raw_data[idx]["rows"]
        
        # è™•ç† Header (é‡è¤‡åç¨±å•é¡Œ)
        unique_header = []
        seen_counts = {}
        for col in header:
            c_str = str(col).strip() if col is not None else ""
            if not c_str: c_str = "Unnamed"
            if c_str in seen_counts:
                seen_counts[c_str] += 1
                new_name = f"{c_str}.{seen_counts[c_str]}"
            else:
                seen_counts[c_str] = 0
                new_name = c_str
            unique_header.append(new_name)
            
        # é–‹å§‹æœå°‹è©² Sheet çš„æ¯ä¸€è¡Œ
        for row_idx, row_str in enumerate(sheet_norm_texts):
            for cfg in prepared_configs:
                is_match = True
                for term in cfg['terms']:
                    if term not in row_str:
                        is_match = False
                        break
                
                if is_match:
                    found_display_names.add(cfg['display'])
                    original_row = all_rows[row_idx]
                    
                    row_dict = {
                        "MatchedKeyword": cfg['display'],
                        "SourceLabel": label,
                        "SheetName": sheet_name
                    }
                    
                    for h_idx, col_name in enumerate(unique_header):
                        val = original_row[h_idx] if h_idx < len(original_row) else None
                        row_dict[col_name] = val
                    
                    all_rows_data.append(row_dict)

    if all_rows_data:
        df_result = pd.DataFrame(all_rows_data)
        # æ¬„ä½æ’åº
        cols = list(df_result.columns)
        sys_cols = ['MatchedKeyword', 'SourceLabel', 'SheetName']
        other_cols = [c for c in cols if c not in sys_cols]
        df_result = df_result[sys_cols + other_cols]
    else:
        df_result = pd.DataFrame()

    all_targets = set(c['display'] for c in prepared_configs)
    missing = all_targets - found_display_names
    
    return df_result, missing

# ==========================================
# 2. BOM Tool é‚è¼¯
# ==========================================

PCB_VENDOR_MAP = {"P": "PRV", "S": "SCC", "U": "æ—­å¾·", "H": "AKM", "D": "ç§‘ä½³"}
PCB_FINISH_MAP = {"G": "åŒ–é‡‘", "N": "é³éˆ€é‡‘", "P": "OSP"}

BASE_OUTPUT_ORDER = [
    "MPN", "Device Name", "ASIC (ç°¡åŒ– BOM)", "Sensor (ç°¡åŒ– BOM)", "PCB ä¾›æ‡‰å•†",
    "éŒ«è†", "PCB ç°¡åŒ– BOM", "é‡‘å±¬æ®¼", "é›»å®¹ / é›»çµ„ / é›»æ„Ÿ", "ç£ç ", "é˜²æ°´è†œ / é‡‘å±¬ç¶²", "Coating"
]

def unify_key(s):
    if not isinstance(s, str): return str(s)
    s = re.sub(r"[\s\(\)\/]", "", s)
    return s.lower()

def format_value(val):
    if pd.isna(val) or val is None: return ""
    val_str = str(val).replace("\n", " ").replace("\r", " ")
    return " ".join(val_str.split())

@st.cache_data(ttl=3600, show_spinner=False)
def load_bom_files(uploaded_files):
    """
    è®€å– BOM Excel æª”æ¡ˆ
    """
    raw_data = [] 
    row_texts = [] 
    
    for file in uploaded_files:
        # è‡ªå‹•åˆ¤æ–· Label
        name = file.name
        label = "CPC" if "CPC" in name.upper() else ("HELE" if "HELE" in name.upper() else name)
        
        try:
            wb = openpyxl.load_workbook(file, read_only=True, data_only=True)
            for sheet_name in wb.sheetnames:
                try:
                    ws = wb[sheet_name]
                    rows = list(ws.iter_rows(values_only=True))
                    if not rows: continue
                    header = rows[0]
                    data_rows = rows[1:]
                    if not data_rows: continue
                    
                    raw_data.append({
                        "label": label,
                        "sheet": sheet_name,
                        "header": header,
                        "rows": data_rows
                    })
                    
                    current_sheet_texts = []
                    for row in data_rows:
                        joined = "".join([str(c) if c is not None else "" for c in row])
                        current_sheet_texts.append(normalize_str(joined))
                    
                    row_texts.append({
                        "label": label,
                        "sheet": sheet_name,
                        "texts": current_sheet_texts
                    })
                except: pass
            wb.close()
        except Exception as e:
            print(f"Error loading {label}: {e}")
            
    return raw_data, row_texts

def parse_pcb_details(green_bom):
    details = []
    if pd.isna(green_bom) or not green_bom: return details
    tokens = re.split(r'[\s\n]+', str(green_bom).strip())
    for token in tokens:
        token = token.strip()
        if len(token) >= 10:
            v_code = token[-4]
            f_code = token[-2]
            vendor = PCB_VENDOR_MAP.get(v_code, None)
            finish = PCB_FINISH_MAP.get(f_code, None)
            details.append({'code': token, 'vendor': vendor, 'finish': finish})
    return details

def get_col_by_keyword(header, keyword, exclude=None):
    target_key = unify_key(keyword)
    for idx, col in enumerate(header):
        col_str = str(col)
        col_key = unify_key(col_str)
        if target_key in col_key:
            if exclude and exclude in col_str: continue
            return idx
    return None

def execute_bom_search(raw_data, row_texts, terms_raw):
    """
    åŸ·è¡Œ BOM æœå°‹
    """
    export_list = []
    found_terms = set()
    
    norm_terms_map = {t: normalize_str(t) for t in terms_raw}
    
    for term in terms_raw:
        n_term = norm_terms_map[term]
        if not n_term: continue
        
        # éæ­·æ‰€æœ‰ Sheet
        for idx, sheet_info in enumerate(row_texts):
            sheet_norm_texts = sheet_info["texts"]
            matched_row_idx = -1
            
            # å°‹æ‰¾åŒ¹é…è¡Œ
            for r_idx, row_str in enumerate(sheet_norm_texts):
                if n_term in row_str:
                    matched_row_idx = r_idx
                    break
            
            if matched_row_idx != -1:
                found_terms.add(term)
                
                # æå–è³‡æ–™
                header = raw_data[idx]["header"]
                row = raw_data[idx]["rows"][matched_row_idx]
                label = sheet_info["label"]
                
                row_data = extract_bom_data(header, row, label, term)
                export_list.append(row_data)

    missing_terms = set(terms_raw) - found_terms
    return export_list, missing_terms

def extract_bom_data(header, row, label, term):
    row_data = {
        "Search Term": term,
        "Source File": label
    }

    def get_val(idx):
        return row[idx] if idx is not None and idx < len(row) else None

    # PCB åˆ†æé‚è¼¯
    pcb_green_idx = get_col_by_keyword(header, "PCB BOM (Green)")
    val_green = get_val(pcb_green_idx)
    pcb_details = parse_pcb_details(val_green)
    vendors = sorted(list(set([d['vendor'] for d in pcb_details if d['vendor']])))
    
    pcb_simple_idx = get_col_by_keyword(header, "PCB ç°¡åŒ– BOM")
    if not pcb_simple_idx: pcb_simple_idx = get_col_by_keyword(header, "PCB ç°¡åŒ–BOM")
    val_simple = format_value(get_val(pcb_simple_idx))
    
    if not vendors and val_simple:
        for code, name in PCB_VENDOR_MAP.items():
            if name in val_simple: vendors.append(name)

    vendors_str = " / ".join(vendors) if vendors else ""

    # æ¬„ä½å®šç¾©
    LAYOUT_PLAN = [
        ("MPN", "normal", ["MPN"]),
        ("Device Name", "normal", ["Device Name"]),
        ("ASIC (ç°¡åŒ– BOM)", "merge", ["ASIC", "ASIC ç°¡åŒ–BOM"]),
        ("Sensor (ç°¡åŒ– BOM)", "merge", ["Sensor ID", "Sensor ç°¡åŒ–BOM"]),
        ("PCB ä¾›æ‡‰å•†", "value", vendors_str),
        ("éŒ«è†", "normal", ["éŒ«è†"]),
        ("PCB ç°¡åŒ– BOM", "normal", ["PCB ç°¡åŒ–BOM"]),
        ("PCB List", "pcb_list", pcb_details),
        ("é‡‘å±¬æ®¼", "normal", ["é‡‘å±¬æ®¼ BOM (Blue)"]),
        ("é›»å®¹ / é›»çµ„ / é›»æ„Ÿ", "normal", ["Indigo"]),
        ("ç£ç ", "normal", ["ç£ç "]),
        ("é˜²æ°´è†œ / é‡‘å±¬ç¶²", "normal", ["é˜²æ°´è†œ"]),
        ("Coating", "normal", ["Coating BOM (Black)"]),
    ]

    for label_text, type_, args in LAYOUT_PLAN:
        final_val = ""
        if type_ == "normal":
            col_key = args[0]
            exclude = "ç°¡åŒ–" if "ç°¡åŒ–" not in label_text and "ç°¡åŒ–" not in col_key else None
            if "Indigo" in col_key: exclude = None
            idx = get_col_by_keyword(header, col_key, exclude=exclude)
            val = format_value(get_val(idx))
            if val: final_val = val
        elif type_ == "merge":
            main_key, sub_key = args
            idx_main = get_col_by_keyword(header, main_key, exclude="ç°¡åŒ–")
            idx_sub = get_col_by_keyword(header, sub_key)
            val_main = format_value(get_val(idx_main))
            val_sub = format_value(get_val(idx_sub))
            if val_main and val_sub:
                final_val = f"{val_main} ({val_sub})" if val_main != val_sub else val_main
            elif val_main: final_val = val_main
            elif val_sub: final_val = val_sub
        elif type_ == "value":
            final_val = str(args)
        elif type_ == "pcb_list":
            for i, item in enumerate(args, 1):
                code = item['code']
                finish = item['finish']
                display = code + (f" ({finish})" if finish else "")
                row_data[f"PCB {i}"] = display
            continue

        if final_val: row_data[label_text] = final_val
        
    return row_data

# ==========================================
# 3. Streamlit UI ä¸»ç¨‹å¼
# ==========================================

st.set_page_config(page_title="Yield & BOM Tool", layout="wide", page_icon="ğŸ“Š")

st.title("ğŸ“Š è‰¯ç‡å ±è¡¨ & BOM æœå°‹å·¥å…·")
st.caption("æ”¯æ´ Excel æ‹–æ›³ä¸Šå‚³ | å¤šæª”æ¡ˆæœå°‹ | è‡ªå‹•å½™æ•´")

tab1, tab2 = st.tabs(["ğŸ“ˆ Yield Analysis", "ğŸ” BOM Search"])

# --- TAB 1: Yield Analysis ---
with tab1:
    col_left, col_right = st.columns([1, 2])
    
    with col_left:
        st.subheader("1. æª”æ¡ˆèˆ‡è¨­å®š")
        yield_files = st.file_uploader(
            "ä¸Šå‚³ Yield Report (Excel)", 
            type=['xlsx', 'xls'], 
            accept_multiple_files=True,
            key="yield_uploader"
        )
        
        # æœå°‹é—œéµå­—
        raw_search = st.text_area(
            "é—œéµå­— (ç©ºæ ¼=AND, é€—è™Ÿ=OR)", 
            height=100,
            placeholder="ä¾‹å¦‚: [Device A], [Device B]\næˆ–: Device A, Device B",
            help="ä½¿ç”¨ [] å¯ä»¥ç²¾ç¢ºæ¯”å°ï¼Œä¾‹å¦‚ [Device Name]ã€‚"
        )
        chk_space = st.checkbox("ç©ºç™½ä»£è¡¨ã€Œæˆ–ã€(OR)", value=False, help="å‹¾é¸å¾Œï¼Œç©ºç™½åˆ†éš”çš„å­—è©æœƒè®Šæˆå¤šå€‹æœå°‹ç›®æ¨™ã€‚")
        
        btn_search_yield = st.button("é–‹å§‹æœå°‹", type="primary", key="btn_yield")

    # è™•ç†è³‡æ–™è®€å– (å¿«å–)
    yield_raw_data = []
    yield_row_texts = []
    
    if yield_files:
        with st.spinner("è®€å–æª”æ¡ˆä¸­..."):
            yield_raw_data, yield_row_texts, sheet_count = load_yield_files(yield_files)
        if sheet_count > 0:
            col_left.success(f"å·²è¼‰å…¥ {len(yield_files)} å€‹æª”æ¡ˆï¼Œå…± {sheet_count} å€‹ Sheet")
    
    with col_right:
        st.subheader("2. åˆ†æçµæœ")
        
        if btn_search_yield and yield_files:
            if not raw_search.strip():
                st.warning("è«‹è¼¸å…¥é—œéµå­—")
            else:
                configs = parse_search_config(raw_search, chk_space)
                # åŸ·è¡Œæœå°‹
                with st.spinner("æœå°‹é‹ç®—ä¸­..."):
                    df_res, missing = execute_yield_search(yield_raw_data, yield_row_texts, configs)
                
                if missing:
                    st.error(f"æœªæ‰¾åˆ°: {', '.join(missing)}")
                
                if not df_res.empty:
                    st.success(f"æ‰¾åˆ° {len(df_res)} ç­†è³‡æ–™")
                    
                    # å­˜å…¥ Session State ä»¥ä¾¿å¾ŒçºŒç¹ªåœ–ä½¿ç”¨ (é¿å…é‡æ•´æ¶ˆå¤±)
                    st.session_state['yield_result'] = df_res
                else:
                    st.info("ç„¡ç¬¦åˆè³‡æ–™")
                    st.session_state['yield_result'] = pd.DataFrame()

        # é¡¯ç¤ºçµæœ (å¦‚æœæœ‰)
        if 'yield_result' in st.session_state and not st.session_state['yield_result'].empty:
            df_display = st.session_state['yield_result']
            
            # åˆ†é ï¼šæ•¸æ“š vs åœ–è¡¨
            sub_t1, sub_t2 = st.tabs(["è©³ç´°æ•¸æ“š", "çµ±è¨ˆåœ–è¡¨"])
            
            with sub_t1:
                st.dataframe(df_display, use_container_width=True)
                
                # Excel ä¸‹è¼‰
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                    # ç°¡å–®æ ¼å¼åŒ–é‚è¼¯
                    unique_sheets = df_display['SheetName'].unique()
                    for s_name in unique_sheets:
                        sub_df = df_display[df_display['SheetName'] == s_name]
                        # ç§»é™¤å…¨ç©ºæ¬„ä½
                        sub_df = sub_df.dropna(axis=1, how='all')
                        safe_name = str(s_name)[:30]
                        sub_df.to_excel(writer, sheet_name=safe_name, index=False)
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰ Excel çµæœ",
                    data=buffer.getvalue(),
                    file_name="yield_result.xlsx",
                    mime="application/vnd.ms-excel"
                )

            with sub_t2:
                st.markdown("#### ç¹ªåœ–è¨­å®š")
                c1, c2, c3, c4 = st.columns(4)
                
                # ç¯©é¸æ•¸å€¼èˆ‡é¡åˆ¥æ¬„ä½
                num_cols = df_display.select_dtypes(include=['number']).columns.tolist()
                all_cols = df_display.columns.tolist()
                
                chart_type = c1.selectbox("åœ–è¡¨é¡å‹", ["Bar (é•·æ¢)", "Line (æŠ˜ç·š)", "Pie (åœ“é¤…)", "Scatter (æ•£ä½ˆ)"])
                x_axis = c2.selectbox("X è»¸ (åˆ†çµ„)", all_cols, index=0)
                y_axis = c3.selectbox("Y è»¸ (æ•¸å€¼)", num_cols if num_cols else all_cols, index=0)
                agg_func = c4.selectbox("è¨ˆç®—æ–¹å¼", ["Sum", "Mean", "Count", "Max"])
                
                if st.button("æ›´æ–°åœ–è¡¨"):
                    try:
                        fig, ax = plt.subplots(figsize=(8, 4))
                        
                        # ç°¡æ˜“è³‡æ–™è™•ç†
                        chart_df = df_display.copy()
                        # å˜—è©¦è½‰æ•¸å€¼
                        chart_df[y_axis] = pd.to_numeric(chart_df[y_axis], errors='coerce').fillna(0)
                        
                        if agg_func == "Count":
                            data = chart_df[x_axis].value_counts()
                        else:
                            agg_map = {"Sum": "sum", "Mean": "mean", "Max": "max"}
                            data = chart_df.groupby(x_axis)[y_axis].agg(agg_map[agg_func])
                        
                        if chart_type == "Bar (é•·æ¢)":
                            data.plot(kind='bar', ax=ax, color='#007AFF')
                        elif chart_type == "Line (æŠ˜ç·š)":
                            data.plot(kind='line', marker='o', ax=ax, color='#007AFF')
                        elif chart_type == "Pie (åœ“é¤…)":
                            data.plot(kind='pie', autopct='%1.1f%%', ax=ax)
                            ax.set_ylabel('')
                        elif chart_type == "Scatter (æ•£ä½ˆ)":
                            ax.scatter(chart_df[x_axis], chart_df[y_axis], color='#007AFF')

                        ax.set_title(f"{agg_func} of {y_axis} by {x_axis}")
                        plt.tight_layout()
                        st.pyplot(fig)
                    except Exception as e:
                        st.error(f"ç¹ªåœ–å¤±æ•—: {e}")


# --- TAB 2: BOM Search ---
with tab2:
    col_b_left, col_b_right = st.columns([1, 2])
    
    with col_b_left:
        st.subheader("1. BOM æª”æ¡ˆè¨­å®š")
        bom_files = st.file_uploader(
            "ä¸Šå‚³ BOM å°æ‡‰è¡¨ (Excel)", 
            type=['xlsx', 'xls'], 
            accept_multiple_files=True,
            key="bom_uploader"
        )
        
        st.info("ç³»çµ±æœƒè‡ªå‹•ä¾æª”åè¾¨è­˜ Label (HELE/CPC/å…¶ä»–)")
        
        bom_input = st.text_area("è¼¸å…¥æ–™è™Ÿ (æ”¯æ´ Excel æ•´æ¬„è²¼ä¸Š)", height=150)
        chk_bom_space = st.checkbox("ç©ºç™½åˆ†éš” (Split by space)", value=False, key="bom_space")
        
        btn_search_bom = st.button("é–‹å§‹æ¯”å°", type="primary", key="btn_bom")

    # è¼‰å…¥ BOM (å¿«å–)
    bom_raw_data = []
    bom_row_texts = []
    if bom_files:
        with st.spinner("å»ºç«‹ BOM ç´¢å¼•..."):
            bom_raw_data, bom_row_texts = load_bom_files(bom_files)
        if bom_raw_data:
            col_b_left.success(f"å·²è¼‰å…¥ {len(bom_files)} å€‹ BOM æª”")

    with col_b_right:
        st.subheader("2. æ¯”å°çµæœ")
        
        if btn_search_bom and bom_files:
            if not bom_input.strip():
                st.warning("è«‹è¼¸å…¥æ–™è™Ÿ")
            else:
                # è§£æè¼¸å…¥
                sep = r'[,\n\r\t\sï¼Œ;]+' if chk_bom_space else r'[,\n\r\tï¼Œ;]+'
                terms_raw = re.split(sep, bom_input)
                clean_terms = [t.strip() for t in terms_raw if t.strip()]
                clean_terms = list(dict.fromkeys(clean_terms)) # å»é‡
                
                st.write(f"æœå°‹ {len(clean_terms)} ç­†æ–™è™Ÿ...")
                
                with st.spinner("æ¯”å°ä¸­..."):
                    res_list, missing_terms = execute_bom_search(bom_raw_data, bom_row_texts, clean_terms)
                
                if missing_terms:
                    st.error(f"âš ï¸ æœªæ‰¾åˆ° ({len(missing_terms)}): {', '.join(missing_terms)}")
                else:
                    st.success("âœ… å…¨éƒ¨æ‰¾åˆ°ï¼")
                
                if res_list:
                    # æ•´ç† DataFrame
                    df_bom = pd.DataFrame(res_list)
                    
                    # å‹•æ…‹æ’åºèˆ‡ PCB æ¬„ä½è™•ç†
                    max_pcb = 0
                    for row in res_list:
                        for k in row.keys():
                            if k.startswith("PCB ") and k[4:].isdigit():
                                max_pcb = max(max_pcb, int(k[4:]))
                    
                    final_headers = ["Search Term", "Source File"]
                    # å˜—è©¦æ’å…¥ PCB æ¬„ä½
                    base_order = list(BASE_OUTPUT_ORDER) # copy
                    try: 
                        ins_idx = base_order.index("PCB ç°¡åŒ– BOM") + 1
                    except: 
                        ins_idx = len(base_order)
                        
                    pcb_cols = [f"PCB {i}" for i in range(1, max_pcb + 1)]
                    
                    final_cols = final_headers + base_order[:ins_idx] + pcb_cols + base_order[ins_idx:]
                    
                    # Reindex
                    df_bom = df_bom.reindex(columns=final_cols)
                    
                    st.dataframe(df_bom, use_container_width=True)
                    
                    # åŒ¯å‡º
                    buffer_bom = io.BytesIO()
                    with pd.ExcelWriter(buffer_bom, engine='openpyxl') as writer:
                        df_bom.to_excel(writer, index=False, sheet_name='Search Results')
                        
                        # è‡ªå‹•èª¿æ•´æ¬„å¯¬ (ç°¡æ˜“ç‰ˆ)
                        ws = writer.sheets['Search Results']
                        for column in ws.columns:
                            col_letter = get_column_letter(column[0].column)
                            ws.column_dimensions[col_letter].width = 20
                            
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰ BOM çµæœ",
                        data=buffer_bom.getvalue(),
                        file_name="BOM_Result.xlsx",
                        mime="application/vnd.ms-excel"
                    )
